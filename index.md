On this page I would like to share some works made by me. You can find my resume [here](https://spb.hh.ru/resume/03d9e35dff096d7a650039ed1f4e4e39726f7a?hhtmFrom=account_login)

List of projects:

- NYSE data dashboard

- Customer Churn Prediction

- ETL pipeline

- Cohort Analysis & dataviz

### NYSE data Dashboard

Within this work I've  done some basic exploratory data analysis, the main purpose of it was to make me familiar with the Dash library. The dashboard itself can be found [here](https://nyse-data.herokuapp.com/) it is fully interactive, you can hover over each graph in order to see the details, you can also zoom into details (view more navigation buttons in the upper right angle)

### Customer Churn Prediction

[Here](https://github.com/yukontaf/projects/blob/master/churn-analysis-famous-trio-imbalanced-data-optuna.ipynb)) I've done some basic EDA, the main purpose: to create efficient model to predict churn of the client given some parameters. I've also planned to build a web app (via streamlit) to make it easy to make predictions specially for the part of audience that doesn't have a configured jupyter notebook at hand. Via this work I demonstrate the abilty not only to build but also a fine tune a ML model with optuna package.

### ETL pipeline

This is not a full-scale work, via this script I would like to demonstrate the fact that I have experience of working with databases, in order to make this working I've created a locally running database, which can be accessed remotely when I start a ngrok tunnel on my local machine. I've also wanted to show that I'm able to load any given table into relational database.

### Cohort Analysis and Dataviz

[Here](https://github.com/yukontaf/projects/blob/master/Case6.ipynb) I've made an attempt to visualize some basic info that was available.
